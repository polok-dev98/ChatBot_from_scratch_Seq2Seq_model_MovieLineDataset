{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f44ab1d3",
   "metadata": {},
   "source": [
    " # Importing the library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d165ffe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7049b5ab",
   "metadata": {},
   "source": [
    "# Load the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b71733",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('movie_lines.txt', encoding='utf-8',errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09bb198a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!',\n",
       " 'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!',\n",
       " 'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.',\n",
       " 'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?',\n",
       " \"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\",\n",
       " 'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow',\n",
       " \"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\",\n",
       " 'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No',\n",
       " 'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?',\n",
       " 'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ae1c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversations = open('movie_conversations.txt', encoding='utf-8',errors='ignore').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16247771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L194', 'L195', 'L196', 'L197']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L198', 'L199']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L200', 'L201', 'L202', 'L203']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L204', 'L205', 'L206']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L207', 'L208']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L271', 'L272', 'L273', 'L274', 'L275']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L276', 'L277']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L280', 'L281']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L363', 'L364']\",\n",
       " \"u0 +++$+++ u2 +++$+++ m0 +++$+++ ['L365', 'L366']\"]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b15b6d3",
   "metadata": {},
   "source": [
    "# Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f48868",
   "metadata": {},
   "outputs": [],
   "source": [
    "exchn = []\n",
    "for conver in conversations:\n",
    "    exchn.append(conver.split(' +++$+++ ')[-1][1:-1].replace(\"'\", \" \").replace(\",\",\"\").split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f855af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['L194', 'L195', 'L196', 'L197'],\n",
       " ['L198', 'L199'],\n",
       " ['L200', 'L201', 'L202', 'L203'],\n",
       " ['L204', 'L205', 'L206'],\n",
       " ['L207', 'L208'],\n",
       " ['L271', 'L272', 'L273', 'L274', 'L275'],\n",
       " ['L276', 'L277'],\n",
       " ['L280', 'L281'],\n",
       " ['L363', 'L364'],\n",
       " ['L365', 'L366']]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchn[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c5bb7ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "diag = {}\n",
    "for line in lines:\n",
    "    diag[line.split(' +++$+++ ')[0]] = line.split(' +++$+++ ')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae26189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating qns inputs and answer targets\n",
    "questions = []\n",
    "answers = []\n",
    "\n",
    "for conver in exchn:\n",
    "    for i in range(len(conver) - 1):\n",
    "        questions.append(diag[conver[i]])\n",
    "        answers.append(diag[conver[i+1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a0d5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ques = []\n",
    "sorted_ans = []\n",
    "for i in range(len(questions)):\n",
    "    if len(questions[i]) < 13:\n",
    "        sorted_ques.append(questions[i])\n",
    "        sorted_ans.append(answers[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ca0bedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cameron.',\n",
       " 'Why?',\n",
       " 'There.',\n",
       " 'Sure have.',\n",
       " 'Hi.',\n",
       " 'I was?',\n",
       " 'Well, no...',\n",
       " 'But',\n",
       " 'What crap?',\n",
       " 'No']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_ques[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217b4f7e",
   "metadata": {},
   "source": [
    "# Text cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef8746ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"i'm\", \"i am\", txt)\n",
    "    txt = re.sub(r\"he's\", \"he is\", txt)\n",
    "    txt = re.sub(r\"she's\", \"she is\", txt)\n",
    "    txt = re.sub(r\"that's\", \"that is\", txt)\n",
    "    txt = re.sub(r\"what's\", \"what is\", txt)\n",
    "    txt = re.sub(r\"where's\", \"where is\", txt)\n",
    "    txt = re.sub(r\"\\'ll\", \" will\", txt)\n",
    "    txt = re.sub(r\"\\'ve\", \" have\", txt)\n",
    "    txt = re.sub(r\"\\'re\", \" are\", txt)\n",
    "    txt = re.sub(r\"\\'d\", \" would\", txt)\n",
    "    txt = re.sub(r\"won't\", \"will not\", txt)\n",
    "    txt = re.sub(r\"can't\", \"can not\", txt)\n",
    "    txt = re.sub(r\"[^\\w\\s]\", \"\", txt)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9be0ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_ques = []\n",
    "clean_ans = []\n",
    "\n",
    "for line in sorted_ques:\n",
    "    clean_ques.append(clean_text(line))\n",
    "        \n",
    "for line in sorted_ans:\n",
    "    clean_ans.append(clean_text(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "394a3859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the thing is cameron  i am at the mercy of a particularly hideous breed of loser  my sister  i can not date until she does',\n",
       " 'unsolved mystery  she used to be really popular when she started high school then it was just like she got sick of it or something',\n",
       " 'where',\n",
       " 'i really really really wanna go but i can not  not unless my sister goes',\n",
       " 'looks like things worked out tonight huh',\n",
       " 'you never wanted to go out with me did you',\n",
       " 'then that is all you had to say',\n",
       " 'you always been this selfish',\n",
       " 'me  this endless blonde babble i am like boring myself',\n",
       " 'okay  you are gonna need to learn how to lie']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_ans[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69269505",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = ' '.join(clean_ans[i].split()[:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d0dc831",
   "metadata": {},
   "outputs": [],
   "source": [
    "## trimming for computational complexity\n",
    "clean_ans=clean_ans[:30000]\n",
    "clean_ques=clean_ques[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f16d9eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vectorizer building\n",
    "word2count = {}\n",
    "\n",
    "for line in clean_ques:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1\n",
    "for line in clean_ans:\n",
    "    for word in line.split():\n",
    "        if word not in word2count:\n",
    "            word2count[word] = 1\n",
    "        else:\n",
    "            word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55fa8293",
   "metadata": {},
   "outputs": [],
   "source": [
    "###  remove less frequent ###\n",
    "thresh = 5\n",
    "\n",
    "vocab = {}\n",
    "word_num = 0\n",
    "for word, count in word2count.items():\n",
    "    if count >= thresh:\n",
    "        vocab[word] = word_num\n",
    "        word_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "03a6279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(clean_ans)):\n",
    "    clean_ans[i] = '<SOS> ' + clean_ans[i] + ' <EOS>'\n",
    "\n",
    "\n",
    "tokens = ['<PAD>', '<EOS>', '<OUT>', '<SOS>']\n",
    "x = len(vocab)\n",
    "for token in tokens:\n",
    "    vocab[token] = x\n",
    "    x += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48193830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3023\n",
      "cameron\n"
     ]
    }
   ],
   "source": [
    "#switch <PAD> value to well's value of 0 for padding purposes later\n",
    "print (vocab['<PAD>'])\n",
    "for i, v in vocab.items():\n",
    "    if v == 0:\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5cc7e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, v in vocab.items():\n",
    "    if v == 0:\n",
    "        vocab[i] = vocab['<PAD>']\n",
    "vocab['<PAD>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "059c7f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "### inv answers dict ###\n",
    "inv_vocab = {w:v for v, w in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1fb69e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inp = []\n",
    "for line in clean_ques:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])\n",
    "        \n",
    "    encoder_inp.append(lst)\n",
    "\n",
    "decoder_inp = []\n",
    "for line in clean_ans:\n",
    "    lst = []\n",
    "    for word in line.split():\n",
    "        if word not in vocab:\n",
    "            lst.append(vocab['<OUT>'])\n",
    "        else:\n",
    "            lst.append(vocab[word])        \n",
    "    decoder_inp.append(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ef67beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inp = pad_sequences(encoder_inp, 13, padding='post', truncating='post')\n",
    "decoder_inp = pad_sequences(decoder_inp, 13, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cceec94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_final_output = []\n",
    "for i in decoder_inp:\n",
    "    decoder_final_output.append(i[1:]) \n",
    "\n",
    "decoder_final_output = pad_sequences(decoder_final_output, 13, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b22e79ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_final_output = to_categorical(decoder_final_output, len(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0b8626",
   "metadata": {},
   "source": [
    "# Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2913a043",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder\n",
    "enc_inp = Input(shape=(13, ))\n",
    "dec_inp = Input(shape=(13, ))\n",
    "\n",
    "\n",
    "VOCAB_SIZE = len(vocab)\n",
    "embed = Embedding(VOCAB_SIZE+1, output_dim=50, input_length=13,trainable=True)\n",
    "enc_embed = embed(enc_inp)\n",
    "enc_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
    "enc_op, h, c = enc_lstm(enc_embed)\n",
    "enc_states = [h, c]\n",
    "\n",
    "#Decoder\n",
    "dec_embed = embed(dec_inp)\n",
    "dec_lstm = LSTM(400, return_sequences=True, return_state=True)\n",
    "dec_op, _, _ = dec_lstm(dec_embed, initial_state=enc_states)\n",
    "\n",
    "dense = Dense(VOCAB_SIZE, activation='softmax')\n",
    "\n",
    "dense_op = dense(dec_op)\n",
    "\n",
    "#final model\n",
    "model_b = Model([enc_inp, dec_inp], dense_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83a7cdce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "938/938 [==============================] - 255s 267ms/step - loss: 3.1046 - acc: 0.4928\n",
      "Epoch 2/2\n",
      "938/938 [==============================] - 258s 275ms/step - loss: 2.7475 - acc: 0.5316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19b662f3ac0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile and train the model\n",
    "model_b.compile(loss='categorical_crossentropy',metrics=['acc'],optimizer='adam')\n",
    "#try more epochs to better result\n",
    "model_b.fit([encoder_inp, decoder_inp],decoder_final_output,epochs=2,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9c8e66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# save the model\n",
    "#model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e90ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the trained model\n",
    "#model =load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe16ed33",
   "metadata": {},
   "source": [
    "# Interference model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5df4e0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoder model\n",
    "enc_model = Model([enc_inp], enc_states)\n",
    "\n",
    "# decoder Model\n",
    "decoder_state_input_h = Input(shape=(400,))\n",
    "decoder_state_input_c = Input(shape=(400,))\n",
    "\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "\n",
    "decoder_outputs, state_h, state_c = dec_lstm(dec_embed , \n",
    "                                    initial_state=decoder_states_inputs)\n",
    "\n",
    "\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "\n",
    "dec_model = Model([dec_inp]+ decoder_states_inputs,\n",
    "                                      [decoder_outputs]+ decoder_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f46fcb",
   "metadata": {},
   "source": [
    "# Generate the prediction and chat with the bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2ed8a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you : who are you?\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "chatbot :  i am not <OUT> \n",
      "==============================================\n",
      "you : q\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "chatbot :  i am not <OUT> \n",
      "==============================================\n"
     ]
    }
   ],
   "source": [
    "prepro1 = \"\"\n",
    "while prepro1 != 'q':\n",
    "    prepro1  = input(\"you : \")\n",
    "    ## prepro1 = \"Hello\"\n",
    "\n",
    "    prepro1 = clean_text(prepro1)\n",
    "    ## prepro1 = \"hello\"\n",
    "\n",
    "    prepro = [prepro1]\n",
    "    ## prepro1 = [\"hello\"]\n",
    "\n",
    "    txt = []\n",
    "    for x in prepro:\n",
    "        # x = \"hello\"\n",
    "        lst = []\n",
    "        for y in x.split():\n",
    "            ## y = \"hello\"\n",
    "            try:\n",
    "                lst.append(vocab[y])\n",
    "                ## vocab['hello'] = 454\n",
    "            except:\n",
    "                lst.append(vocab['<OUT>'])\n",
    "        txt.append(lst)\n",
    "\n",
    "    ## txt = [[454]]\n",
    "    txt = pad_sequences(txt, 13, padding='post')\n",
    "\n",
    "    ## txt = [[454,0,0,0,.........13]]\n",
    "\n",
    "    stat = enc_model.predict( txt )\n",
    "\n",
    "    empty_target_seq = np.zeros( ( 1 , 1) )\n",
    "     ##   empty_target_seq = [0]\n",
    "    empty_target_seq[0, 0] = vocab['<SOS>']\n",
    "    ##    empty_target_seq = [255]\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_translation = ''\n",
    "\n",
    "    while not stop_condition :\n",
    "\n",
    "        dec_outputs , h, c= dec_model.predict([ empty_target_seq] + stat )\n",
    "        decoder_concat_input = dense(dec_outputs)\n",
    "        ## decoder_concat_input = [0.1, 0.2, .4, .0, ...............]\n",
    "\n",
    "        sampled_word_index = np.argmax( decoder_concat_input[0, -1, :] )\n",
    "        ## sampled_word_index = [2]\n",
    "\n",
    "        sampled_word = inv_vocab[sampled_word_index] + ' '\n",
    "\n",
    "        ## inv_vocab[2] = 'hi'\n",
    "        ## sampled_word = 'hi '\n",
    "\n",
    "        if sampled_word != '<EOS> ':\n",
    "            decoded_translation += sampled_word  \n",
    "\n",
    "        if sampled_word == '<EOS> ' or len(decoded_translation.split()) > 13:\n",
    "            stop_condition = True \n",
    "\n",
    "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
    "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
    "        ## <SOS> - > hi\n",
    "        ## hi --> <EOS>\n",
    "        stat = [h, c]  \n",
    "\n",
    "    print(\"chatbot : \", decoded_translation )\n",
    "    print(\"==============================================\")      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abdace6",
   "metadata": {},
   "source": [
    "# Try more data and more epochs for better result .Enjoy!!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
